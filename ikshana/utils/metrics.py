import torch


def accuracy_function(
    ground_truth: torch.Tensor, predictions: torch.Tensor
) -> float:
    """
    accuracy_function: Calculate accuracy between ground truth and predictions.

    Parameters
    ----------
    ground_truth : torch.Tensor
        Ground Truth labels that are annotated.
    predictions : torch.Tensor
        Predictions generated by model, that need to be compared to ground
        truth labels.

    Returns
    -------
    float
        Accuracy value on comparison between ground_truth and predictions.
    """
    correct: float = torch.eq(ground_truth, predictions).sum().item()
    accuracy: float = (correct / len(predictions)) * 100

    return accuracy
